"""
Agent æ ¸å¿ƒç±» - å¯¹åº” packages/core/src/agent/agent.ts

è¿™æ˜¯ PyMidscene çš„æ ¸å¿ƒå…¥å£ï¼Œæä¾› AI é©±åŠ¨çš„è‡ªåŠ¨åŒ–èƒ½åŠ›ã€‚
"""

from typing import Optional, Dict, Any, List, Union, Tuple
import time
import asyncio

from ..ai_model import call_ai
from ..ai_model.prompts import (
    system_prompt_to_locate_element,
    find_element_prompt,
    system_prompt_to_extract,
    extract_data_prompt,
    parse_xml_extraction_response,
)
from ..agent.task_cache import TaskCache, PlanningCache, LocateCache
from ..dump import ExecutionRecorder, SessionRecorder, create_session_recorder
from ..types import ScreenshotItem
from ...web_integration.base import AbstractInterface
from ...shared.types import Size, Rect, LocateResultElement
from ...shared.logger import logger
from ...shared.utils import calculate_center, format_bbox, adapt_bbox
from ...shared.env import (
    ModelConfigManager,
    ModelConfig,
    get_global_model_config_manager,
    INTENT_DEFAULT,
)


class Agent:
    """
    AI é©±åŠ¨çš„è‡ªåŠ¨åŒ– Agent

    æ•´åˆäº† AI æ¨¡å‹ã€ç¼“å­˜ç³»ç»Ÿå’Œæµè§ˆå™¨æ§åˆ¶ï¼Œæä¾›é«˜çº§çš„è‡ªåŠ¨åŒ–èƒ½åŠ›ã€‚

    ä½¿ç”¨æ–¹å¼ï¼š
    1. é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®æ¨¡å‹ï¼ˆæ¨èï¼‰ï¼š
        os.environ["MIDSCENE_MODEL_NAME"] = "qwen-vl-max"
        os.environ["OPENAI_API_KEY"] = "your-key"
        os.environ["OPENAI_BASE_URL"] = "https://dashscope.aliyuncs.com/compatible-mode/v1"
        os.environ["MIDSCENE_MODEL_FAMILY"] = "qwen2.5-vl"

        agent = Agent(interface)

    2. é€šè¿‡ model_config å­—å…¸é…ç½®ï¼š
        agent = Agent(interface, model_config={
            "MIDSCENE_MODEL_NAME": "qwen-vl-max",
            "OPENAI_API_KEY": "your-key",
            "OPENAI_BASE_URL": "https://...",
            "MIDSCENE_MODEL_FAMILY": "qwen2.5-vl",
        })
    """

    def __init__(
        self,
        interface: AbstractInterface,
        model_config: Optional[Dict[str, Any]] = None,
        cache_id: Optional[str] = None,
        cache_strategy: str = "read-write",
        cache_dir: Optional[str] = None,
        enable_recording: bool = True,  # é»˜è®¤å¯ç”¨è®°å½•
        driver_type: str = "playwright",
        report_dir: Optional[str] = None,
    ):
        """
        åˆå§‹åŒ– Agent

        Args:
            interface: è®¾å¤‡æ¥å£ï¼ˆWebPage ç­‰ï¼‰
            model_config: æ¨¡å‹é…ç½®å­—å…¸ï¼Œé”®ä¸ºç¯å¢ƒå˜é‡åç§°
                - MIDSCENE_MODEL_NAME: æ¨¡å‹åç§°
                - OPENAI_API_KEY / MIDSCENE_MODEL_API_KEY: API å¯†é’¥
                - OPENAI_BASE_URL / MIDSCENE_MODEL_BASE_URL: API åŸºç¡€ URL
                - MIDSCENE_MODEL_FAMILY: æ¨¡å‹å®¶æ—ï¼ˆqwen2.5-vl, doubao-vision ç­‰ï¼‰
            cache_id: ç¼“å­˜ ID
            cache_strategy: ç¼“å­˜ç­–ç•¥ï¼ˆread-only, read-write, write-onlyï¼‰
            cache_dir: ç¼“å­˜ç›®å½•
            enable_recording: æ˜¯å¦å¯ç”¨æ‰§è¡Œè®°å½•ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
            driver_type: é©±åŠ¨ç±»å‹ï¼ˆplaywright, selenium ç­‰ï¼‰
            report_dir: æŠ¥å‘Šä¿å­˜ç›®å½•ï¼ˆé»˜è®¤ä¸ºå½“å‰ç›®å½•ï¼‰
        """
        self.interface = interface
        self.driver_type = driver_type

        # åˆå§‹åŒ–æ¨¡å‹é…ç½®ç®¡ç†å™¨
        if model_config:
            # ä½¿ç”¨ä¼ å…¥çš„é…ç½®ï¼ˆéš”ç¦»æ¨¡å¼ï¼‰
            self.model_config_manager = ModelConfigManager(model_config)
        else:
            # ä½¿ç”¨å…¨å±€é…ç½®ç®¡ç†å™¨ï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            self.model_config_manager = get_global_model_config_manager()

        # åˆå§‹åŒ–ç¼“å­˜
        self.task_cache: Optional[TaskCache] = None
        if cache_id:
            self.task_cache = TaskCache(
                cache_id=cache_id,
                is_cache_result_used=(cache_strategy != "write-only"),
                cache_dir=cache_dir,
                strategy=cache_strategy
            )
            logger.info(f"Task cache initialized: {cache_id}")

        # åˆå§‹åŒ–ä¼šè¯è®°å½•å™¨ï¼ˆæ–°çš„æ—¥å¿—ç³»ç»Ÿï¼‰
        self.enable_recording = enable_recording
        self.session_recorder: Optional[SessionRecorder] = None
        self.recorder: Optional[ExecutionRecorder] = None  # ä¿æŒå‘åå…¼å®¹

        if enable_recording:
            self.session_recorder = create_session_recorder(
                driver_type=driver_type,
                base_dir=report_dir,
                auto_save=True
            )
            # åŒæ—¶ä¿ç•™æ—§çš„ recorder ä»¥å…¼å®¹
            self.recorder = ExecutionRecorder(
                name="Agent Execution",
                description="Automated execution"
            )
            logger.info(f"Session recording enabled: {self.session_recorder.session_id}")

        logger.info(
            f"Agent initialized: "
            f"cache={'enabled' if cache_id else 'disabled'}, "
            f"recording={'enabled' if enable_recording else 'disabled'}"
        )

    def _get_model_config(self, intent: str = INTENT_DEFAULT) -> ModelConfig:
        """è·å–æ¨¡å‹é…ç½®"""
        return self.model_config_manager.get_model_config(intent)

    def _build_messages(
        self,
        system_prompt: str,
        user_prompt: str,
        screenshot_b64: str
    ) -> List[Dict[str, Any]]:
        """æ„å»º AI æ¶ˆæ¯"""
        return [
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{screenshot_b64}"
                        }
                    },
                    {
                        "type": "text",
                        "text": user_prompt
                    }
                ]
            }
        ]

    def _call_ai_with_config(
        self,
        messages: List[Dict[str, Any]],
        intent: str = INTENT_DEFAULT
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨é…ç½®è°ƒç”¨ AI
        
        æ”¯æŒä¸¤ç§è°ƒç”¨æ–¹å¼ï¼š
        1. httpx ç›´æ¥è¯·æ±‚ï¼ˆé€‚ç”¨äºåä»£ã€Gemini ç­‰ï¼‰- æ›´å…¼å®¹
        2. OpenAI SDKï¼ˆé€‚ç”¨äºæ ‡å‡† OpenAI å…¼å®¹ APIï¼‰- å¤‡ç”¨
        """
        config = self._get_model_config(intent)

        # ç»Ÿä¸€ä½¿ç”¨ httpx ç›´æ¥è¯·æ±‚ï¼Œæ›´å…¼å®¹å„ç§åä»£å’Œ API æ ¼å¼
        return self._call_with_httpx(config, messages)

    def _call_with_httpx(
        self,
        config: ModelConfig,
        messages: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ httpx ç›´æ¥è¯·æ±‚ï¼ˆå‚è€ƒ GeminiHttpClient å®ç°ï¼‰
        
        å…¼å®¹ï¼š
        - Gemini åä»£ï¼ˆOpenAI å…¼å®¹æ ¼å¼ï¼‰
        - è±†åŒ…/åƒé—®ç­‰ OpenAI å…¼å®¹ API
        - ä»»ä½• OpenAI æ ¼å¼çš„åä»£æœåŠ¡
        """
        import httpx

        # æ„é€ è¯·æ±‚ URL
        base = (config.openai_base_url or "").rstrip("/")
        if not base:
            raise ValueError("MIDSCENE_MODEL_BASE_URL is required")
        
        # æ™ºèƒ½æ‹¼æ¥ URLï¼š
        # 1. å¦‚æœ base_url å·²ç»åŒ…å«ç‰ˆæœ¬è·¯å¾„ï¼ˆ/v1, /v2, /v3 ç­‰ï¼‰ï¼Œç›´æ¥æ‹¼ /chat/completions
        # 2. å¦åˆ™è‡ªåŠ¨åŠ  /v1/chat/completionsï¼ˆé€‚ç”¨äºåä»£ï¼‰
        import re as _re
        if _re.search(r'/v\d+$', base):
            # å·²ç»åŒ…å«ç‰ˆæœ¬è·¯å¾„ï¼š/v1, /v3 ç­‰
            url = f"{base}/chat/completions"
        else:
            # æ²¡æœ‰ç‰ˆæœ¬è·¯å¾„ï¼Œè‡ªåŠ¨åŠ  /v1ï¼ˆé€‚ç”¨äºåä»£ï¼‰
            url = f"{base}/v1/chat/completions"
        
        logger.debug(f"Request URL: {url}")

        # æ„é€ è¯·æ±‚å¤´
        headers = {
            "Authorization": f"Bearer {config.openai_api_key}",
            "Content-Type": "application/json",
        }

        # æ„é€ è¯·æ±‚ä½“
        data = {
            "model": config.model_name,
            "messages": messages,
            "max_tokens": 4096,
        }

        # temperature ä»…åœ¨éé›¶æ—¶è®¾ç½®ï¼ˆæœ‰äº› API ä¸æ”¯æŒï¼‰
        if config.temperature is not None and config.temperature > 0:
            data["temperature"] = config.temperature

        # å‘é€è¯·æ±‚ï¼ˆtrust_env=False ç¦ç”¨ç³»ç»Ÿä»£ç†ï¼‰
        with httpx.Client(
            trust_env=False,
            timeout=config.timeout or 120
        ) as client:
            response = client.post(url, headers=headers, json=data)

        if response.status_code != 200:
            logger.error(f"API request failed: status={response.status_code}, body={response.text[:500]}")
            raise RuntimeError(
                f"API request failed (status {response.status_code}): {response.text[:200]}"
            )

        result = response.json()

        # æå–å“åº”å†…å®¹ï¼ˆOpenAI æ ¼å¼ï¼‰
        content = result["choices"][0]["message"]["content"]

        # æå– usage ä¿¡æ¯
        usage = None
        if "usage" in result:
            usage = {
                "prompt_tokens": result["usage"].get("prompt_tokens"),
                "completion_tokens": result["usage"].get("completion_tokens"),
                "total_tokens": result["usage"].get("total_tokens"),
            }

        return {
            "content": content,
            "usage": usage,
            "raw_response": result
        }

    async def ai_locate(
        self,
        prompt: str,
        use_cache: bool = True
    ) -> Optional[LocateResultElement]:
        """
        ä½¿ç”¨ AI å®šä½é¡µé¢å…ƒç´ 

        Args:
            prompt: å…ƒç´ æè¿°ï¼ˆå¦‚ "ç™»å½•æŒ‰é’®"ï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            å®šä½ç»“æœæˆ– None
        """
        logger.info(f"AI Locate: '{prompt}'")

        # å¼€å§‹è®°å½•æ­¥éª¤ï¼ˆSessionRecorderï¼‰
        if self.session_recorder:
            self.session_recorder.start_step("locate", prompt)

        # å¼€å§‹è®°å½•ä»»åŠ¡ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰
        if self.recorder:
            task = self.recorder.start_task("locate", param=prompt)

        # æ£€æŸ¥ç¼“å­˜ï¼ˆä¸ JS ç‰ˆæœ¬å¯¹é½ï¼šä½¿ç”¨ XPath å®šä½ï¼‰
        if use_cache and self.task_cache:
            cache_result = self.task_cache.match_locate_cache(prompt)
            if cache_result:
                logger.info(f"Cache hit for locate: '{prompt}'")
                cache_data = cache_result.cache_content.cache
                
                # JS ç‰ˆæœ¬æ ¼å¼ï¼šä½¿ç”¨ xpaths å®šä½å…ƒç´ 
                if cache_data and "xpaths" in cache_data:
                    xpaths = cache_data["xpaths"]
                    if xpaths and len(xpaths) > 0:
                        xpath = xpaths[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ª XPath
                        logger.info(f"Using cached XPath: {xpath[:80]}...")
                        
                        # é€šè¿‡ XPath è·å–å…ƒç´ ä½ç½®
                        element_info = await self.interface.get_element_by_xpath(xpath)
                        if element_info:
                            rect = element_info["rect"]
                            center = element_info["center"]
                            
                            element = LocateResultElement(
                                description=prompt,
                                center=center,
                                rect=rect
                            )
                            
                            logger.info(f"Cache hit (XPath): '{prompt}' at {center}")
                            
                            # è®°å½•ç¼“å­˜å‘½ä¸­
                            if self.recorder:
                                self.recorder.finish_task(status="finished", output=element)
                            if self.session_recorder:
                                self.session_recorder.complete_step("success")
                            
                            return element
                        else:
                            # XPath æ‰¾ä¸åˆ°å…ƒç´ ï¼Œå¯èƒ½é¡µé¢ç»“æ„å˜åŒ–ï¼Œéœ€è¦é‡æ–° AI å®šä½
                            logger.warning(f"Cached XPath not found on page, re-locating: '{prompt}'")

        # è·å–æˆªå›¾
        screenshot_b64 = await self.interface.screenshot()
        size = await self.interface.get_size()

        # è®°å½•æˆªå›¾ï¼ˆSessionRecorderï¼‰
        if self.session_recorder:
            self.session_recorder.record_screenshot_before(screenshot_b64)

        # è®°å½•æˆªå›¾ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰
        if self.recorder:
            screenshot_item = ScreenshotItem(screenshot_b64)
            self.recorder.record_screenshot(screenshot_item, timing="before")

        # è·å–æ¨¡å‹é…ç½®
        config = self._get_model_config(INTENT_DEFAULT)
        model_family = config.model_family or "qwen2.5-vl"

        # å‡†å¤‡æ¶ˆæ¯
        messages = self._build_messages(
            system_prompt=system_prompt_to_locate_element(model_family),
            user_prompt=find_element_prompt(prompt),
            screenshot_b64=screenshot_b64
        )

        # è°ƒç”¨ AI
        start_time = time.time()
        result = self._call_ai_with_config(messages, INTENT_DEFAULT)
        elapsed_ms = (time.time() - start_time) * 1000

        # è®°å½• AI ä½¿ç”¨ä¿¡æ¯
        if self.session_recorder and result.get('usage'):
            self.session_recorder.record_ai_info(
                model=config.model_name,
                tokens=result['usage'].get('total_tokens'),
                response=result.get('content', '')[:500]
            )

        if self.recorder and result.get('usage'):
            usage_info = result['usage'].copy()
            usage_info['time_cost'] = elapsed_ms / 1000
            usage_info['model_name'] = config.model_name
            self.recorder.record_ai_usage(usage_info)

        logger.info(
            f"AI locate completed: {elapsed_ms:.0f}ms, "
            f"tokens={result.get('usage', {}).get('total_tokens', 0) if result.get('usage') else 0}"
        )

        # è§£æç»“æœ
        from ...shared.utils import safe_parse_json, extract_json_from_code_block
        # å…ˆæå– JSONï¼ˆå¤„ç† markdown ä»£ç å—ï¼‰
        json_text = extract_json_from_code_block(result["content"])
        response_data = safe_parse_json(json_text)

        if not response_data or "bbox" not in response_data:
            logger.warning(f"AI locate failed: no bbox in response")
            if self.recorder:
                self.recorder.finish_task(status="failed", error=ValueError("No bbox in response"))
            if self.session_recorder:
                self.session_recorder.fail_step("No bbox in response")
            return None

        bbox = response_data["bbox"]
        if not bbox or (isinstance(bbox, list) and len(bbox) < 2):
            logger.warning(f"AI locate failed: invalid bbox {bbox}")
            if self.recorder:
                self.recorder.finish_task(status="failed", error=ValueError(f"Invalid bbox: {bbox}"))
            if self.session_recorder:
                self.session_recorder.fail_step(f"Invalid bbox: {bbox}")
            return None

        # æ ¹æ®æ¨¡å‹ç±»å‹é€‚é… bbox åæ ‡ï¼ˆå…³é”®ï¼šdoubao è¿”å›çš„æ˜¯å½’ä¸€åŒ– 0-1000 åæ ‡ï¼‰
        model_family = config.model_family or "qwen2.5-vl"
        img_width = int(size.get('width', 1280))
        img_height = int(size.get('height', 800))
        
        try:
            adapted_bbox = adapt_bbox(
                bbox=bbox,
                width=img_width,
                height=img_height,
                right_limit=img_width,
                bottom_limit=img_height,
                model_family=model_family
            )
            logger.debug(f"Adapted bbox: {bbox} -> {adapted_bbox} (model={model_family}, size={img_width}x{img_height})")
        except Exception as e:
            logger.warning(f"Failed to adapt bbox: {e}, using raw values")
            adapted_bbox = tuple(bbox) if isinstance(bbox, list) else bbox

        # è½¬æ¢ä¸º Rect å’Œä¸­å¿ƒç‚¹
        rect = format_bbox(adapted_bbox)
        center = calculate_center(rect)

        element = LocateResultElement(
            description=prompt,
            center=center,
            rect=rect
        )

        # è®°å½•å…ƒç´ å®šä½ç»“æœï¼ˆSessionRecorder - å¸¦å¯è§†åŒ–æ ‡è®°ï¼‰
        if self.session_recorder:
            bbox_tuple: Tuple[int, int, int, int] = (
                int(rect['left']),
                int(rect['top']),
                int(rect['left'] + rect['width']),
                int(rect['top'] + rect['height'])
            )
            center_tuple: Tuple[int, int] = (int(center[0]), int(center[1]))
            self.session_recorder.record_element_location(
                bbox=bbox_tuple,
                center=center_tuple,
                description=prompt,
                draw_marker=True
            )

        # ä¿å­˜åˆ°ç¼“å­˜ï¼ˆä¸ JS ç‰ˆæœ¬å¯¹é½ï¼šå­˜å‚¨ XPath è€Œä¸æ˜¯åæ ‡ï¼‰
        if use_cache and self.task_cache:
            # è·å–å…ƒç´ çš„ XPathï¼ˆé€šè¿‡å…ƒç´ ä¸­å¿ƒç‚¹å®šä½ DOM å…ƒç´ ï¼‰
            xpath = await self.interface.get_element_xpath(center[0], center[1])
            if xpath:
                self.task_cache.append_cache(LocateCache(
                    type="locate",
                    prompt=prompt,
                    cache={
                        "xpaths": [xpath]  # ä¸ JS ç‰ˆæœ¬æ ¼å¼å®Œå…¨ä¸€è‡´
                    }
                ))
                logger.debug(f"Cached XPath for '{prompt}': {xpath[:80]}...")
            else:
                logger.warning(f"Could not get XPath for element at {center}, cache not saved")

        # å®Œæˆä»»åŠ¡è®°å½•
        if self.recorder:
            self.recorder.finish_task(status="finished", output=element)
        if self.session_recorder:
            self.session_recorder.complete_step("success")

        logger.info(f"Element located: {prompt} at {center}")

        return element

    async def ai_locate_with_scroll_retry(
        self,
        prompt: str,
        use_cache: bool = True,
        max_scroll_attempts: int = 3,
        scroll_distance: int = 500
    ) -> Optional[LocateResultElement]:
        """
        å¸¦æ»šåŠ¨é‡è¯•çš„æ™ºèƒ½å…ƒç´ å®šä½ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        å·¥ä½œæµç¨‹ï¼š
        1. ç¬¬1æ¬¡ï¼šåœ¨å½“å‰è§†å£å°è¯•å®šä½
        2. å¤±è´¥ â†’ å‘ä¸‹æ»šåŠ¨ 500px â†’ ç¬¬2æ¬¡å°è¯•
        3. å¤±è´¥ â†’ å†æ¬¡æ»šåŠ¨ 500px â†’ ç¬¬3æ¬¡å°è¯•
        4. æ‰¾åˆ°å…ƒç´ åè‡ªåŠ¨æ»šåŠ¨åˆ°è§†å£ä¸­å¿ƒï¼ˆä¸ JS ç‰ˆæœ¬å¯¹é½ï¼‰
        
        Args:
            prompt: å…ƒç´ æè¿°
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜ï¼ˆç¬¬ä¸€æ¬¡å°è¯•æ—¶ä½¿ç”¨ï¼Œé‡è¯•æ—¶ä¸ä½¿ç”¨ï¼‰
            max_scroll_attempts: æœ€å¤§æ»šåŠ¨å°è¯•æ¬¡æ•°ï¼ˆé»˜è®¤3æ¬¡ï¼‰
            scroll_distance: æ¯æ¬¡æ»šåŠ¨è·ç¦»ï¼ˆåƒç´ ï¼Œé»˜è®¤500ï¼‰
        
        Returns:
            å®šä½ç»“æœæˆ– None
        """
        logger.info(f"AI Locate with scroll retry: '{prompt}' (max_attempts={max_scroll_attempts})")
        
        for attempt in range(max_scroll_attempts):
            # å°è¯•å®šä½å…ƒç´ 
            # ç¬¬ä¸€æ¬¡å°è¯•ä½¿ç”¨ç¼“å­˜ï¼Œåç»­é‡è¯•ä¸ä½¿ç”¨ç¼“å­˜ï¼ˆå› ä¸ºé¡µé¢ä½ç½®å·²æ”¹å˜ï¼‰
            should_use_cache = use_cache and (attempt == 0)
            element = await self.ai_locate(prompt, use_cache=should_use_cache)
            
            if element:
                logger.info(
                    f"Element '{prompt}' found on attempt {attempt + 1}/{max_scroll_attempts} "
                    f"at {element.center}"
                )
                return element
            
            # å¦‚æœè¿˜æœ‰é‡è¯•æœºä¼šï¼Œæ»šåŠ¨é¡µé¢
            if attempt < max_scroll_attempts - 1:
                logger.info(
                    f"Element '{prompt}' not found in current viewport, "
                    f"scrolling down {scroll_distance}px (attempt {attempt + 1}/{max_scroll_attempts})"
                )
                
                # æ»šåŠ¨é¡µé¢
                await self.interface.scroll('down', scroll_distance)
                
                # ç­‰å¾…é¡µé¢ç¨³å®š
                await asyncio.sleep(0.5)
        
        logger.warning(
            f"Element '{prompt}' not found after {max_scroll_attempts} scroll attempts"
        )
        return None

    async def ai_click(self, prompt: str, enable_scroll_retry: bool = True) -> bool:
        """
        ä½¿ç”¨ AI å®šä½å¹¶ç‚¹å‡»å…ƒç´ 

        Args:
            prompt: å…ƒç´ æè¿°
            enable_scroll_retry: æ˜¯å¦å¯ç”¨æ»šåŠ¨é‡è¯•ï¼ˆé»˜è®¤ Trueï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # å¼€å§‹è®°å½•æ­¥éª¤ï¼ˆSessionRecorderï¼‰
        if self.session_recorder:
            self.session_recorder.start_step("click", prompt)
            # è·å–æ“ä½œå‰æˆªå›¾
            screenshot_before = await self.interface.screenshot()
            self.session_recorder.record_screenshot_before(screenshot_before)

        # å¼€å§‹è®°å½•ä»»åŠ¡ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰
        if self.recorder:
            task = self.recorder.start_task("click", param=prompt)

        # ğŸ”‘ ä½¿ç”¨æ»šåŠ¨é‡è¯•æœºåˆ¶å®šä½å…ƒç´ 
        if enable_scroll_retry:
            element = await self.ai_locate_with_scroll_retry(prompt)
        else:
            element = await self.ai_locate(prompt)
        
        if not element:
            logger.error(f"Cannot locate element: {prompt}")
            if self.recorder:
                self.recorder.finish_task(status="failed", error=ValueError(f"Cannot locate: {prompt}"))
            if self.session_recorder:
                self.session_recorder.fail_step(f"Cannot locate: {prompt}")
            return False

        # è®°å½•å…ƒç´ ä½ç½®
        if self.session_recorder:
            rect = element.rect
            bbox_tuple: Tuple[int, int, int, int] = (
                int(rect['left']),
                int(rect['top']),
                int(rect['left'] + rect['width']),
                int(rect['top'] + rect['height'])
            )
            center_tuple: Tuple[int, int] = (int(element.center[0]), int(element.center[1]))
            self.session_recorder.record_element_location(
                bbox=bbox_tuple,
                center=center_tuple,
                description=prompt,
                draw_marker=True
            )

        # ç‚¹å‡»ä¸­å¿ƒç‚¹
        x, y = element.center
        await self.interface.click(x, y)

        # è·å–æ“ä½œåæˆªå›¾
        if self.session_recorder:
            screenshot_after = await self.interface.screenshot()
            self.session_recorder.record_screenshot_after(screenshot_after)
            self.session_recorder.complete_step("success")

        logger.info(f"Clicked: {prompt} at ({x}, {y})")

        # å®Œæˆä»»åŠ¡è®°å½•
        if self.recorder:
            self.recorder.finish_task(status="finished", output={"x": x, "y": y})

        return True

    async def ai_input(self, prompt: str, text: str, enable_scroll_retry: bool = True) -> bool:
        """
        ä½¿ç”¨ AI å®šä½å¹¶è¾“å…¥æ–‡æœ¬

        Args:
            prompt: å…ƒç´ æè¿°
            text: è¦è¾“å…¥çš„æ–‡æœ¬
            enable_scroll_retry: æ˜¯å¦å¯ç”¨æ»šåŠ¨é‡è¯•ï¼ˆé»˜è®¤ Trueï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        # å¼€å§‹è®°å½•æ­¥éª¤ï¼ˆSessionRecorderï¼‰
        if self.session_recorder:
            self.session_recorder.start_step("input", f"{prompt}: {text}")
            screenshot_before = await self.interface.screenshot()
            self.session_recorder.record_screenshot_before(screenshot_before)

        # å¼€å§‹è®°å½•ä»»åŠ¡ï¼ˆæ—§ç‰ˆå…¼å®¹ï¼‰
        if self.recorder:
            task = self.recorder.start_task("input", param={"prompt": prompt, "text": text})

        # ğŸ”‘ ä½¿ç”¨æ»šåŠ¨é‡è¯•æœºåˆ¶å®šä½å…ƒç´ 
        if enable_scroll_retry:
            element = await self.ai_locate_with_scroll_retry(prompt)
        else:
            element = await self.ai_locate(prompt)
        
        if not element:
            logger.error(f"Cannot locate element: {prompt}")
            if self.recorder:
                self.recorder.finish_task(status="failed", error=ValueError(f"Cannot locate: {prompt}"))
            if self.session_recorder:
                self.session_recorder.fail_step(f"Cannot locate: {prompt}")
            return False

        # ç‚¹å‡»å¹¶è¾“å…¥
        x, y = element.center
        await self.interface.input_text(text, x, y)

        # è·å–æ“ä½œåæˆªå›¾
        if self.session_recorder:
            screenshot_after = await self.interface.screenshot()
            self.session_recorder.record_screenshot_after(screenshot_after)
            self.session_recorder.complete_step("success")

        logger.info(f"Input to {prompt}: '{text}'")

        # å®Œæˆä»»åŠ¡è®°å½•
        if self.recorder:
            self.recorder.finish_task(status="finished", output={"text": text})

        return True

    async def ai_query(
        self,
        data_demand: Union[Dict[str, str], str],
        use_cache: bool = False
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ AI ä»é¡µé¢æå–æ•°æ®

        Args:
            data_demand: æ•°æ®éœ€æ±‚ï¼ˆå­—å…¸æˆ–å­—ç¬¦ä¸²ï¼‰
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            æå–çš„æ•°æ®
        """
        logger.info(f"AI Query: {data_demand}")

        # å¼€å§‹è®°å½•ä»»åŠ¡
        if self.recorder:
            task = self.recorder.start_task("query", param=data_demand)

        # è·å–æˆªå›¾
        screenshot_b64 = await self.interface.screenshot()

        # è®°å½•æˆªå›¾
        if self.recorder:
            screenshot_item = ScreenshotItem(screenshot_b64)
            self.recorder.record_screenshot(screenshot_item, timing="before")

        # å‡†å¤‡æ¶ˆæ¯
        messages = self._build_messages(
            system_prompt=system_prompt_to_extract(),
            user_prompt=extract_data_prompt(data_demand),
            screenshot_b64=screenshot_b64
        )

        # è°ƒç”¨ AI
        start_time = time.time()
        config = self._get_model_config(INTENT_DEFAULT)
        result = self._call_ai_with_config(messages, INTENT_DEFAULT)
        elapsed_ms = (time.time() - start_time) * 1000

        # è®°å½• AI ä½¿ç”¨ä¿¡æ¯
        if self.recorder and result.get('usage'):
            usage_info = result['usage'].copy()
            usage_info['time_cost'] = elapsed_ms / 1000
            usage_info['model_name'] = config.model_name
            self.recorder.record_ai_usage(usage_info)

        logger.info(
            f"AI query completed: {elapsed_ms:.0f}ms, "
            f"tokens={result.get('usage', {}).get('total_tokens', 0) if result.get('usage') else 0}"
        )

        # è§£æ XML å“åº”
        try:
            parsed = parse_xml_extraction_response(result["content"])
            logger.info(f"Data extracted: {parsed['data']}")

            # å®Œæˆä»»åŠ¡è®°å½•
            if self.recorder:
                self.recorder.finish_task(status="finished", output=parsed)

            return parsed
        except Exception as e:
            logger.error(f"Failed to parse extraction response: {e}")
            if self.recorder:
                self.recorder.finish_task(status="failed", error=e)
            raise

    async def ai_assert(
        self,
        assertion: str,
        message: str = ""
    ) -> bool:
        """
        ä½¿ç”¨ AI æ–­è¨€é¡µé¢çŠ¶æ€

        Args:
            assertion: æ–­è¨€æè¿°ï¼ˆå¦‚ "é¡µé¢æ˜¾ç¤ºç™»å½•æˆåŠŸ"ï¼‰
            message: é”™è¯¯æ¶ˆæ¯

        Returns:
            æ–­è¨€æ˜¯å¦é€šè¿‡

        Raises:
            AssertionError: å¦‚æœæ–­è¨€å¤±è´¥
        """
        logger.info(f"AI Assert: '{assertion}'")

        # å¼€å§‹è®°å½•ä»»åŠ¡
        if self.recorder:
            task = self.recorder.start_task("assert", param=assertion)

        # è·å–æˆªå›¾
        screenshot_b64 = await self.interface.screenshot()

        # è®°å½•æˆªå›¾
        if self.recorder:
            screenshot_item = ScreenshotItem(screenshot_b64)
            self.recorder.record_screenshot(screenshot_item, timing="before")

        # å‡†å¤‡æ¶ˆæ¯
        messages = self._build_messages(
            system_prompt='You are an AI assistant that verifies UI states. Return JSON: {"pass": true/false, "thought": "reasoning"}',
            user_prompt=f"Verify: {assertion}",
            screenshot_b64=screenshot_b64
        )

        # è°ƒç”¨ AI
        start_time = time.time()
        config = self._get_model_config(INTENT_DEFAULT)
        result = self._call_ai_with_config(messages, INTENT_DEFAULT)
        elapsed_ms = (time.time() - start_time) * 1000

        # è®°å½• AI ä½¿ç”¨ä¿¡æ¯
        if self.recorder and result.get('usage'):
            usage_info = result['usage'].copy()
            usage_info['time_cost'] = elapsed_ms / 1000
            usage_info['model_name'] = config.model_name
            self.recorder.record_ai_usage(usage_info)

        # è§£æç»“æœ
        from ...shared.utils import safe_parse_json
        response_data = safe_parse_json(result["content"])

        if not response_data:
            error = ValueError("Failed to parse assertion response")
            if self.recorder:
                self.recorder.finish_task(status="failed", error=error)
            raise error

        passed = response_data.get("pass", False)
        thought = response_data.get("thought", "")

        if passed:
            logger.info(f"Assertion passed: {assertion}")
            if self.recorder:
                self.recorder.finish_task(status="finished", output={"pass": True, "thought": thought})
            return True
        else:
            error_msg = message or f"Assertion failed: {assertion}\nReason: {thought}"
            logger.error(error_msg)
            if self.recorder:
                self.recorder.finish_task(status="failed", error=AssertionError(error_msg))
            raise AssertionError(error_msg)

    async def ai_act(
        self,
        task_prompt: str,
        use_cache: bool = True
    ) -> bool:
        """
        ä½¿ç”¨ AI æ‰§è¡Œå¤æ‚ä»»åŠ¡ï¼ˆç®€åŒ–ç‰ˆï¼‰

        Args:
            task_prompt: ä»»åŠ¡æè¿°
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        logger.info(f"AI Act: '{task_prompt}'")

        # è¿™æ˜¯ç®€åŒ–ç‰ˆå®ç°
        # å®Œæ•´å®ç°éœ€è¦ï¼š
        # 1. ä»»åŠ¡è§„åˆ’ï¼ˆç”Ÿæˆ YAML å·¥ä½œæµï¼‰
        # 2. ä»»åŠ¡æ‰§è¡Œå™¨ï¼ˆæ‰§è¡Œæ¯ä¸ªæ­¥éª¤ï¼‰
        # 3. é”™è¯¯å¤„ç†å’Œé‡è¯•

        # ç›®å‰ä»…ä½œä¸ºç¤ºä¾‹ï¼Œå®é™…åº”è¯¥è°ƒç”¨è§„åˆ’å’Œæ‰§è¡Œé€»è¾‘
        logger.warning("ai_act is simplified version, full implementation pending")

        return True

    def get_cache_stats(self) -> Optional[Dict[str, Any]]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        if self.task_cache:
            return self.task_cache.get_stats()
        return None

    def finish(self) -> Optional[str]:
        """
        ç»“æŸä¼šè¯å¹¶ç”ŸæˆæŠ¥å‘Š

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœå¯ç”¨äº†è®°å½•ï¼‰
        """
        if self.session_recorder:
            report_path = self.session_recorder.finish()
            logger.info(f"Session finished, report saved to: {report_path}")
            return report_path
        return None

    def save_report(self) -> Optional[str]:
        """
        æ‰‹åŠ¨ä¿å­˜æŠ¥å‘Š

        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        if self.session_recorder:
            return self.session_recorder.save_report()
        return None

    def get_report_dir(self) -> Optional[str]:
        """è·å–æŠ¥å‘Šç›®å½•è·¯å¾„"""
        if self.session_recorder:
            return str(self.session_recorder.run_manager.report_dir)
        return None

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨é€€å‡º - è‡ªåŠ¨ä¿å­˜æŠ¥å‘Š"""
        if exc_type and self.session_recorder:
            # å¦‚æœæœ‰å¼‚å¸¸ï¼Œæ ‡è®°å½“å‰æ­¥éª¤å¤±è´¥
            if self.session_recorder.current_step:
                self.session_recorder.fail_step(str(exc_val))

        self.finish()
        return False


__all__ = ["Agent"]
